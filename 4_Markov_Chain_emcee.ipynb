{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"norms\"\n",
    "\n",
    "import os\n",
    "import emcee\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "from pyazr import azure2\n",
    "from multiprocess import Pool, current_process\n",
    "\n",
    "# Restrict processes to one thread only\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Define the data labels (in AZURE2 order)\n",
    "labels = [\"Meyer et al. (1976) - 84.3 deg\",\n",
    "          \"Meyer et al. (1976) - 114.5 deg\",\n",
    "          \"Meyer et al. (1976) - 144.1 deg\", \n",
    "          \"LUNA HPGe (2023)\", \n",
    "          \"LUNA BGO (2023)\",\n",
    "          \"Felsenkeller (2023)\",\n",
    "          \"ATOMKI (2023)\",\n",
    "          \"Notre Dame (2023) - 0 deg\",\n",
    "          \"Notre Dame (2023) - 55 deg\",\n",
    "          \"Burtebaev et al. (2008)\",\n",
    "          \"Lamb et al. (1957)\",\n",
    "          \"Bailey et al. (1950)\",\n",
    "          \"Vogl et al. (1963)\",\n",
    "          \"Rolfs et al. (1974) - 0 deg\",\n",
    "          \"Rolfs et al. (1974) - 90 deg\"]\n",
    "\n",
    "# Define the parameters prior distributions\n",
    "priors = [\n",
    "    stats.norm(1.63,0.12),\n",
    "\n",
    "    stats.uniform(2.30, 0.10), stats.uniform(0, 1e6), stats.uniform(-10, 20),\n",
    "    stats.uniform(-1e8,2e8),\n",
    "\n",
    "    stats.uniform(3.45, 0.10), stats.uniform(0, 1e6), stats.uniform(-10, 20), stats.uniform(-10, 20),\n",
    "    stats.uniform(-1e8,2e8), stats.uniform(-1e8,2e8),\n",
    "\n",
    "    stats.uniform(3.50, 0.10), stats.uniform(0, 1e6),\n",
    "    \n",
    "    stats.lognorm(0.05),\n",
    "    stats.lognorm(0.05),\n",
    "    stats.lognorm(0.05),\n",
    "    stats.lognorm(0.069),\n",
    "    stats.lognorm(0.079),\n",
    "    stats.lognorm(0.10),\n",
    "    stats.lognorm(0.06),\n",
    "    stats.lognorm(0.10),\n",
    "    stats.lognorm(0.10),\n",
    "    stats.lognorm(0.10),\n",
    "    stats.uniform(0, 100),\n",
    "    stats.uniform(0, 100),\n",
    "    stats.uniform(0, 100),\n",
    "    stats.uniform(0, 100),\n",
    "    stats.uniform(0, 100)\n",
    "]\n",
    "\n",
    "# Minimization variables\n",
    "nsteps   = 10000        # How many steps should each walker take?\n",
    "nprocs   = 7            # How many Python processes do you want to allocate?\n",
    "ndim     = len(priors)  # How many parameters are you fitting?\n",
    "nwalkers = 2 * ndim     # How many walkers do you want to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the .azr file and set the external capture file to speed up the calculation\n",
    "azr = azure2('12c_pg.azr', nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the initial values from AZURE2\n",
    "theta0 = azr.params\n",
    "ntheta = len(theta0)\n",
    "\n",
    "# We'll read the data from the output file since it's already in the center-of-mass frame\n",
    "y = azr.cross\n",
    "yerr = azr.cross_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior log probability\n",
    "def lnPi( theta ):\n",
    "    return np.sum([pi.logpdf(t) for (pi, t) in zip(priors, theta)])\n",
    "\n",
    "# Log likelihood\n",
    "def lnL( theta, proc=0 ):\n",
    "    res = 0\n",
    "    mu = azr.calculate( theta[:ntheta], proc=proc )\n",
    "    for i in range( len( mu ) ):\n",
    "        idx = ntheta + i\n",
    "        res += np.sum( -0.5 * np.log(2 * np.pi * pow(yerr[i], 2) ) - 0.5 * pow((mu[i] - y[i] * theta[idx]) / (yerr[i] * theta[idx]), 2) )\n",
    "    return res\n",
    "\n",
    "# Posterior log probability\n",
    "def lnP( theta ):\n",
    "    try: proc = int(current_process().name.split('-')[1]) - 1 # We want to get the numbe r of the process to call the right AZURE2 port\n",
    "    except: proc = 0 \n",
    "    lnpi = lnPi( theta )\n",
    "    if not np.isfinite( lnpi ): return -np.inf\n",
    "    return lnL( theta, proc=proc ) + lnpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some good guesses for the initial walker positions\n",
    "data = np.loadtxt( \"results/{}/samples.txt\".format(DIR) )\n",
    "mean = np.mean( data, axis=0 )\n",
    "\n",
    "# Prepare initial walker positions\n",
    "p0 = np.zeros( (nwalkers, ndim) )\n",
    "for i in range(nwalkers):\n",
    "    for j in range(ndim):\n",
    "        if( j not in [1, 5, 11] ): p0[i,j] = np.sign(mean[j]) * stats.uniform( abs(mean[j]) * 0.5, abs(mean[j]) * 1.0 ).rvs()\n",
    "        else: p0[i,j] = np.sign(mean[j]) * stats.uniform( abs(mean[j]) * 0.99, abs(mean[j]) * 0.02 ).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the file to write the chains\n",
    "backend = emcee.backends.HDFBackend('results/emcee/samples_{}.h5'.format(DIR)) \n",
    "backend.reset(nwalkers, len(priors))\n",
    "\n",
    "# Run the sampling\n",
    "with Pool(processes=nprocs) as pool:\n",
    "    sampler = emcee.EnsembleSampler( nwalkers, ndim, lnP, pool=pool, backend=backend ) \n",
    "    state = sampler.run_mcmc( p0, nsteps, progress=True, tune=True )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
